# ğŸ§¾ 1099 Reconciliation Pipeline

![Python](https://img.shields.io/badge/Python-3.11%2B-blue)
![Pandas](https://img.shields.io/badge/Pandas-2.0+-green)
![License](https://img.shields.io/badge/License-MIT-blue)
![Status](https://img.shields.io/badge/Status-Portfolio-brightgreen)
![CI](https://github.com/manuel-reyes-ml/1099_reconciliation_pipeline/actions/workflows/ci.yml/badge.svg?branch=main)

Automated data pipeline for **reconciling retirement plan distributions** between Relius (distribution exports) and Matrix (disbursement/1099 exports). Standardizes inputs, runs three matching/correction engines (A/B/C), and produces Matrix-ready correction recommendations (tax codes, taxable amount, Roth basis year).

> ğŸ›¡ï¸ **Privacy First:** All data in this repository is synthetic. Original project built for production with real participant data (SSN, tax codes) - cannot be shared for compliance reasons.

### Recruiter Pitch

I built this project to showcase **both Data Engineering and Data Analytics in a real finance workflow**: ingesting messy Excel exports from Relius and Matrix (plus Relius demographics and Roth basis extracts), normalizing them into a canonical schema, applying auditable business rules across **Engine A (inherited plan matching)**, **Engine B (age-based non-Roth tax codes)**, and **Engine C (Roth taxable + Roth tax-code logic)**, and generating **Matrix-ready 1099-R correction files** for review and execution.

---

## ğŸ“š Table of Contents
- [Why This Project?](#-why-this-project)
- [Key Features](#-key-features)
- [Data Analysis Process](#-data-analysis-process)
- [Repository Structure](#ï¸-repository-structure)
- [Tech Stack](#ï¸-tech-stack)
- [CI & Testing](#-ci--testing)
- [Getting Started](#-getting-started)
- [Results & Impact](#-results--impact)
- [What I Learned](#-what-i-learned)
- [About Me](#-about-me)

---

## ğŸ’¡ Why This Project?

### The Problem
Financial institutions managing retirement plans face a critical challenge: **1099 tax forms must be accurate**. When two legacy systems (Relius for transactions, Matrix for disbursements) don't sync properly, the consequences are severe:

- âŒ Incorrect 1099 forms mailed to participants
- âŒ Reissued tax forms (costly and time-consuming)
- âŒ Compliance risks and audit findings
- âŒ Extra workload for operations teams (manual reconciliation)
- âŒ Frustrated participants and plan sponsors

### My Solution
Built an **automated reconciliation pipeline** that:
- âœ… Normalizes multiple Excel exports into a canonical schema
- âœ… Applies deterministic match keys with config-driven tolerances
- âœ… Runs specialized engines for inherited, age-based, and Roth workflows
- âœ… Flags corrections and review items before 1099s are mailed
- âœ… Generates Matrix-ready correction files with suggested updates

### Personal Context
While working in retirement plan administration, I witnessed the operational pain of manual Excel-based reconciliation. This project demonstrates how Python automation can solve real business problems and deliver immediate ROI.

---

## ğŸ“¸ Project Preview

> **Status:** Portfolio pipeline with synthetic demo data

### Sample Output
```
=== 1099 Reconciliation Results (Illustrative) ===

Total Transactions Processed: 10,247
âœ“ Perfect Matches: 9,845 (96.1%)
âš  Matches Needing Correction: 312 (3.0%)
âš  Date Out of Range: 58 (0.6%)
â“ Unmatched (Relius): 32 (0.3%)
â“ Unmatched (Matrix): 0 (0.0%)
```

### Visualizations
```
[Match Rate by Plan]
[Mismatch Types Distribution]
[Monthly Reconciliation Trends]
[Monthly Correction Reason Trends]

(Placeholders - actual charts generated by pipeline)
```

---

## ğŸ¯ Key Features

### ğŸ“Š **Multi-System Data Integration**
- Reads Excel exports from Relius distributions, Relius demographics, Relius Roth basis, and Matrix disbursements
- Handles inconsistent formats, missing data, duplicate entries
- Normalizes dates, amounts, SSNs, plan IDs, and tax codes to canonical names

### ğŸ§¹ **Intelligent Data Cleaning**
- SSN validation and formatting (123-45-6789 â†’ 123456789)
- Date standardization across different formats
- Amount normalization (handles cents, negatives, rounding)
- Tax code standardization (7, 07, Code 7 â†’ 7)

### ğŸ” **Smart Matching Logic**
- Deterministic matching with config-driven keys (plan_id + ssn + gross_amt)
- Date lag tolerance enforced from `MATCHING_CONFIG` (Matrix txn_date occurs after Relius export)
- Explicit match_status labels: match_no_action, match_needs_correction, date_out_of_range, unmatched_relius, unmatched_matrix

### ğŸ§© **Engines A/B/C**
- **Engine A (Inherited matching):** Reconciles Relius vs Matrix distributions and applies inherited-plan tax-code rules (4/G).
- **Engine B (Age-based, non-Roth):** Uses Relius demo data (DOB/term date) to suggest non-Roth tax codes (1/2/7); excludes rollovers and inherited plans.
- **Engine C (Roth taxable):** Uses Matrix + Relius demo + Roth basis to suggest taxable amount, Roth initial year, and Roth tax codes; excludes inherited plans but does not exclude rollovers.

### ğŸ“ˆ **Business Intelligence**
- Review-ready outputs: match_status, correction_reason, and action fields for QA
- Notebook-friendly data frames for analysis and stakeholder summaries

### ğŸ“‹ **Actionable Outputs**
- **Correction file:** Excel sheet with recommended actions
  - UPDATE_1099: Safe to correct in Matrix
  - INVESTIGATE: Requires manual review
- **Audit trail:** match_status and correction_reason fields for review and traceability

---

## ğŸ§  Data Analysis Process

### 1ï¸âƒ£ Problem Framing
**Business Question:** Which discrepancies require 1099 corrections?

**Key Decisions:**
- Define match criteria (plan_id + ssn + gross_amt with date lag tolerance)
- Centralize thresholds in `config.py` (MATCHING_CONFIG, AGE_TAXCODE_CONFIG, ROTH_TAXABLE_CONFIG)
- Separate workflows into Engine A/B/C to keep rules auditable

---

### 2ï¸âƒ£ Data Understanding

**Relius Distribution Export (Transactions)**
```
Columns (canonical): plan_id, ssn, gross_amt, exported_date, dist_code_1,
         dist_name, tax_year
Records: varies by plan and tax year
Issues: duplicate entries, inconsistent headers, mixed date formats
```

**Matrix Export (Disbursement/1099 Data)**
```
Columns (canonical): plan_id, ssn, gross_amt, fed_taxable_amt, txn_date,
         tax_code_1, tax_code_2, transaction_id, matrix_account,
         roth_initial_contribution_year
Records: varies by plan and tax year
Issues: SSN format variations, rounding differences, mixed tax code strings
```

**Relius Demo Export (Participant Master)**
```
Columns (canonical): plan_id, ssn, dob, term_date, first_name, last_name
Purpose: age-based tax code rules for Engine B/C
```

**Relius Roth Basis Export**
```
Columns (canonical): plan_id, ssn, first_roth_tax_year, roth_basis_amt
Purpose: Roth taxable analysis and Roth start-year corrections
```

**See:** `docs/data_dictionary.md` for complete field definitions

---

### 3ï¸âƒ£ Data Cleaning Pipeline
```python
from src.config import MATRIX_COLUMN_MAP
from src.core.normalizers import normalize_ssn_series, normalize_tax_code_series, to_date_series

# Canonical column mapping + normalization
df = df.rename(columns=MATRIX_COLUMN_MAP)
df["ssn"] = normalize_ssn_series(df["ssn"])
df["txn_date"] = to_date_series(df["txn_date"])
df["tax_code_1"] = normalize_tax_code_series(df["tax_code_1"])
```

Optional date filtering (range + months) is configurable via `DateFilterConfig`:
```python
from src.config import DateFilterConfig
from src.cleaning.clean_matrix import clean_matrix
from src.cleaning.clean_relius import clean_relius

date_filter = DateFilterConfig(
    date_start="2025-07-01",
    date_end="2025-09-30",
    months=["July", "Aug", 9],
)

matrix_clean = clean_matrix(matrix_raw, date_filter=date_filter)
relius_clean = clean_relius(relius_raw, date_filter=date_filter)
```

**Results:** Clean data written to `data/processed/` (gitignored)

---

### 4ï¸âƒ£ Matching Algorithm

**Step 1: Exact Match**
```sql
-- Conceptual SQL for matching logic
JOIN relius r ON matrix m
WHERE r.plan_id = m.plan_id
  AND r.ssn = m.ssn
  AND r.gross_amt = m.gross_amt
  AND DATEDIFF(m.txn_date, r.exported_date) BETWEEN 0 AND 10
```

**Step 2: Classification**
- âœ… **match_no_action:** Joined and within date tolerance
- âš ï¸ **match_needs_correction:** Joined, within tolerance, but codes need update
- âš ï¸ **date_out_of_range:** Joined, but outside date tolerance window
- â“ **unmatched_relius / unmatched_matrix:** Record exists in one system only

**Step 3: Prioritization**
1. Inherited-plan corrections (Engine A: code 4/G rules)
2. Age-based non-Roth corrections (Engine B: 1/2/7 rules)
3. Roth taxable + Roth tax-code corrections (Engine C: taxable amount, start year, B* rules)

---

### 5ï¸âƒ£ Analysis & Insights

**Review Checks:**
- Match status counts by plan and tax year
- Counts of recommended updates vs investigate-only items
- Roth taxable vs non-Roth correction mix
- Date out-of-range counts for operational follow-up

**Example Questions:**
- "Which plans have the highest number of inherited-plan corrections?"
- "Are Roth taxable updates concentrated in specific transaction years?"
- "How many records are flagged for missing basis year data?"

---

### 6ï¸âƒ£ Correction File

**Output Structure:**
```
Transaction Id | Transaction Date | Participant SSN | Participant Name | Matrix Account |
Current Tax Code 1 | Current Tax Code 2 | New Tax Code | New Taxable Amount |
New First Year contrib | Reason | Action
```

**Action Codes:**
- `UPDATE_1099`: Safe to correct in Matrix
- `INVESTIGATE`: Requires manual review (missing/ambiguous data)

**Business Impact:**
- Operations team reviews a focused correction list instead of full exports
- Corrections applied before 1099 mailing deadlines
- Audit trail for compliance

---

## ğŸ—‚ï¸ Repository Structure
```
1099-reconciliation-pipeline/
â”‚
â”œâ”€â”€ README.md                           # You are here
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ requirements-dev.txt                # Dev/test dependencies
â”œâ”€â”€ .gitignore                          # Excludes real data
â”œâ”€â”€ LICENSE                             # MIT License
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample/                         # Synthetic data (SAFE to share)
â”‚   â”‚   â”œâ”€â”€ matrix_sample.xlsx         # ~95 sample disbursements
â”‚   â”‚   â”œâ”€â”€ relius_demo_sample.xlsx    # Demo extract (DOB/term date)
â”‚   â”‚   â”œâ”€â”€ relius_roth_basis_sample.xlsx
â”‚   â”‚   â””â”€â”€ relius_sample.xlsx         # ~100 sample transactions
â”‚   â”œâ”€â”€ raw/                            # Real exports (GITIGNORED)
â”‚   â””â”€â”€ processed/                      # Cleaned data (GITIGNORED)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ business_context.md             # Problem narrative
â”‚   â”œâ”€â”€ data_dictionary.md              # Field definitions
â”‚   â””â”€â”€ matching_logic.md               # Algorithm documentation
â”‚
â”œâ”€â”€ logs/                               # Runtime logs (gitignored)
â”‚
â”œâ”€â”€ src/                                # Core pipeline modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                       # Settings (tolerances, paths)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_data.py                # Excel â†’ pandas DataFrames
â”‚   â”‚   â”œâ”€â”€ normalizers.py              # Canonical field normalization
â”‚   â”‚   â”œâ”€â”€ validators.py               # Validation helpers
â”‚   â”‚   â””â”€â”€ generate_sample_data.py     # Synthetic sample generator
â”‚   â”œâ”€â”€ cleaning/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clean_relius.py             # Relius cleaning logic
â”‚   â”‚   â”œâ”€â”€ clean_relius_demo.py        # Relius demographics cleaning
â”‚   â”‚   â”œâ”€â”€ clean_relius_roth_basis.py  # Relius Roth basis cleaning
â”‚   â”‚   â””â”€â”€ clean_matrix.py             # Matrix cleaning logic
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ match_planid.py             # Engine A (inherited matching)
â”‚   â”‚   â”œâ”€â”€ age_taxcode_analysis.py     # Engine B (age-based non-Roth)
â”‚   â”‚   â””â”€â”€ roth_taxable_analysis.py    # Engine C (Roth taxable)
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ match_planid_visualization.py
â”‚   â”‚   â”œâ”€â”€ age_taxcode_visualization.py
â”‚   â”‚   â””â”€â”€ roth_taxable_visualization.py
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ export_utils.py             # Export helpers
â”‚       â””â”€â”€ build_correction_file.py    # Generate Excel output
â”‚
â”œâ”€â”€ notebooks/                          # Analysis walkthrough
â”‚   â”œâ”€â”€ 00_generate_sample_data.ipynb
â”‚   â”œâ”€â”€ 01_data_understanding.ipynb
â”‚   â”œâ”€â”€ 02_cleaning_pipeline.ipynb
â”‚   â”œâ”€â”€ 03_match_planid_analysis.ipynb
â”‚   â”œâ”€â”€ 04_match_demo_analysis.ipynb
â”‚   â”œâ”€â”€ 05_match_roth_basis_analysis.ipynb
â”‚   â”œâ”€â”€ 06_age_taxcode_visualization.ipynb
â”‚   â”œâ”€â”€ 07_match_planid_visualization.ipynb
â”‚   â””â”€â”€ 08_roth_taxable_visualization.ipynb
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/                        # Generated charts (png)
â”‚   â”‚   â”œâ”€â”€ match_planid/
â”‚   â”‚   â”œâ”€â”€ age_taxcode/
â”‚   â”‚   â””â”€â”€ roth_taxable/
â”‚   â”œâ”€â”€ outputs/                        # Timestamped correction files (production default)
â”‚   â”‚   â”œâ”€â”€ match_planid/
â”‚   â”‚   â”œâ”€â”€ age_taxcode/
â”‚   â”‚   â””â”€â”€ roth_taxable/
â”‚   â””â”€â”€ samples/                        # Sample-mode outputs
â”‚       â”œâ”€â”€ figures/                    # Sample-mode charts
â”‚       â”‚   â”œâ”€â”€ match_planid/
â”‚       â”‚   â”œâ”€â”€ age_taxcode/
â”‚       â”‚   â””â”€â”€ roth_taxable/
â”‚       â”œâ”€â”€ match_planid/
â”‚       â”œâ”€â”€ age_taxcode/
â”‚       â””â”€â”€ roth_taxable/
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ 1099r_correct_form.xlsx         # Matrix correction template
â”‚
â”œâ”€â”€ tests/                              # Unit tests (optional)
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ roth_taxable/
â”‚   â”œâ”€â”€ validators/
â”‚   â””â”€â”€ visualization/
```

---

## ğŸ› ï¸ Tech Stack

| Category | Technology | Purpose |
|----------|-----------|---------|
| **Language** | Python 3.11+ | Core logic |
| **Data Processing** | pandas | DataFrames, joins, grouping |
| **Numeric** | numpy | Tolerance checks, calculations |
| **Excel I/O** | openpyxl | Read/write .xlsx files |
| **Visualization** | matplotlib, plotly | Charts and dashboards |
| **Notebooks** | Jupyter | Analysis documentation |
| **Version Control** | Git, GitHub | Code management |

**Why These Tools:**
- **pandas:** Industry standard for Excel-like data operations in Python
- **openpyxl:** Preserves Excel formatting (important for ops team)
- **Jupyter:** Makes analysis reproducible and shareable

---

## âœ… CI & Testing

- GitHub Actions runs pytest on every push and pull request to `main`.
- Tests execute across a Python 3.11+ matrix aligned with supported releases.
- CI installs `requirements-dev.txt` and runs `pytest -q` for fast feedback.

**Recruiter Note:** Automated testing validates business-rule changes before they reach production workflows.

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.11 or higher
- pip (Python package manager)
- Git

### Installation

**1. Clone the repository**
```bash
git clone https://github.com/manuel-reyes-ml/1099-reconciliation-pipeline.git
cd 1099-reconciliation-pipeline
```

**2. Create virtual environment (recommended)**
```bash
# Create venv
python -m venv .venv

# Activate (Mac/Linux)
source .venv/bin/activate

# Activate (Windows PowerShell)
.venv\Scripts\Activate.ps1

# Activate (Windows Command Prompt)
.venv\Scripts\activate.bat
```

**3. Install dependencies**
```bash
pip install -r requirements.txt

# Or install individually:
pip install pandas numpy openpyxl matplotlib jupyter
```

**4. Verify installation**
```bash
python -c "import pandas; print('âœ“ Pandas installed')"
python -c "import openpyxl; print('âœ“ openpyxl installed')"
```

---

### Usage

**Sample data defaults (public repo)**
- Loader functions honor `USE_SAMPLE_DATA_DEFAULT` in `src/config.py` when `path` is omitted.
- Keep it set to `True` to use `data/sample/`. Regenerate synthetic inputs from the repo root with `python -m src.core.generate_sample_data` or run `notebooks/00_generate_sample_data.ipynb`.

#### Option 1: Run Complete Pipeline (Command Line)
Runs the Engine A inherited-plan workflow using sample data in `data/sample/`.
```bash
# Engine A: inherited-plan reconciliation + correction file
python -m src.outputs.build_correction_file
```

#### Option 2: Interactive Analysis (Jupyter)
```bash
# Launch Jupyter
jupyter notebook

# Open notebooks in order:
# 1. notebooks/00_generate_sample_data.ipynb
# 2. notebooks/01_data_understanding.ipynb
# 3. notebooks/02_cleaning_pipeline.ipynb
# 4. notebooks/03_match_planid_analysis.ipynb
# 5. notebooks/04_match_demo_analysis.ipynb
# 6. notebooks/05_match_roth_basis_analysis.ipynb
# 7. notebooks/06_age_taxcode_visualization.ipynb
# 8. notebooks/07_match_planid_visualization.ipynb
# 9. notebooks/08_roth_taxable_visualization.ipynb
# (Engine B/C workflows are covered in 04-06 and 07-08 or can be run from scripts)
```

#### Option 3: Use as Module
```python
from src.core.load_data import load_relius_excel, load_matrix_excel
from src.cleaning.clean_relius import clean_relius
from src.cleaning.clean_matrix import clean_matrix
from src.engines.match_planid import reconcile_relius_matrix
from src.outputs.build_correction_file import build_correction_dataframe, write_correction_file
from src.outputs.export_utils import write_df_excel

# Load and clean
relius_raw = load_relius_excel("data/sample/relius_sample.xlsx")
matrix_raw = load_matrix_excel("data/sample/matrix_sample.xlsx")
relius_clean = clean_relius(relius_raw)
matrix_clean = clean_matrix(matrix_raw)

# Engine A matching
# Default plan scope uses DEFAULT_RECONCILIATION_PLAN_IDS unless plan_ids is provided.
matches = reconcile_relius_matrix(relius_clean, matrix_clean)
corrections = build_correction_dataframe(matches)
write_correction_file(corrections, "output.xlsx")
write_correction_file(corrections, engine="match_planid")

# Optional: ad-hoc exports (engine-aware output directory)
write_df_excel(corrections, filename_prefix="match_planid_export", engine="match_planid")
```

---

### Expected Output

**Console (sample mode default):**
```bash
Corrections written to: reports/samples/match_planid/correction_file_20241208_153045.xlsx
Total corrections: 6
```

Production default uses `reports/outputs/<engine>/correction_file_[date].xlsx` when `USE_SAMPLE_DATA_DEFAULT=False` and an engine is provided.

**Files Created (default output):**
- `reports/samples/<engine>/correction_file_[date].xlsx` - Sample mode default
- `reports/outputs/<engine>/correction_file_[date].xlsx` - Production mode default
If `engine` is omitted, outputs stay under `reports/samples/` or `reports/outputs/`. Explicit `output_path` values override these defaults.
`write_df_excel(..., engine="<engine>")` writes to `reports/outputs/<engine>/` by default.
Figure outputs from visualization notebooks follow `USE_SAMPLE_DATA_DEFAULT`: `reports/samples/figures/<engine>/` in sample mode and `reports/figures/<engine>/` in production.

---

## ğŸ“ˆ Results & Impact

### Quantified Business Value

| Metric | Manual Baseline | Automated Pipeline | Outcome |
|--------|----------------|-------------------|---------|
| **Time per reconciliation** | Hours of manual review | Automated run + targeted review | Material reduction |
| **Match accuracy** | Manual spot checks | Deterministic rules + review list | More consistent |
| **1099 error discovery** | Reactive | Pre-mailing review | Lower risk |
| **Processing capacity** | Limited by manual effort | Batch processing across plans | Higher throughput |
| **Cost savings** | Labor-intensive | Reduced manual effort | Operational savings |

### Real-World Impact

**Operations Team:**
- Uses a structured correction file rather than ad hoc spreadsheets
- Focuses review on specific match_status and correction_reason flags

**Compliance:**
- Receives a consistent audit trail with suggested corrections and rationale

---

## ğŸ“š What I Learned

### Technical Skills Demonstrated

**Data Engineering:**
- âœ… ETL pipeline design (Extract, Transform, Load)
- âœ… Data validation and quality checks
- âœ… Handling messy real-world data (missing values, duplicates, format inconsistencies)
- âœ… Performance optimization with vectorized pandas operations

**Data Analysis:**
- âœ… Exploratory data analysis (EDA) on financial systems
- âœ… Statistical matching with tolerance thresholds
- âœ… KPI definition and tracking
- âœ… Data visualization for stakeholders

**Business Acumen:**
- âœ… Understanding financial regulations (1099-R reporting)
- âœ… Translating business requirements to technical specs
- âœ… Prioritizing features by business impact
- âœ… Delivering actionable outputs for non-technical users

**Software Engineering:**
- âœ… Modular code design (separate concerns)
- âœ… Version control with Git
- âœ… Documentation for maintainability
- âœ… Privacy-first development (synthetic data)

### Challenges Overcome

1. **Rounding Errors:** Discovered systems store amounts differently (dollars vs cents)
   - **Solution:** Normalize to integer cents to avoid float precision issues

2. **Date Inconsistencies:** 3 different date formats across systems
   - **Solution:** Build robust date parser with fallback logic

3. **SSN Variations:** 123456789, 123-45-6789, XXX-XX-6789 (partial)
   - **Solution:** Regex-based normalization + validation

4. **Performance:** Early version was too slow for large batches
   - **Solution:** Vectorized pandas operations and minimized per-row loops

---

## ğŸ›£ï¸ Roadmap

### âœ… Phase 1: Core Pipeline (Completed)
- [x] Excel data loading
- [x] Data cleaning modules
- [x] Matching algorithm
- [x] Correction file generation
- [x] Jupyter analysis notebooks

### âœ… Phase 2: Documentation & Portfolio Packaging (Completed)
- [x] Synthetic data for portfolio
- [x] Comprehensive documentation
- [x] Privacy-first cleanup of sample outputs

### ğŸš§ Phase 3: Enhancements (In Progress)
- [ ] Web dashboard (Streamlit) for interactive analysis
- [ ] Automated email alerts for high-priority mismatches
- [ ] Historical trending analysis (multi-year comparisons)
- [ ] Integration with API endpoints (move beyond Excel exports)

### ğŸ“‹ Phase 4: Advanced Features (Future)
- [ ] Machine learning for anomaly detection
- [ ] Predictive analytics (forecast mismatch likelihood)
- [ ] Multi-system reconciliation (add 3rd system)
- [ ] Real-time monitoring dashboard

---

## ğŸ”’ Privacy & Compliance

### Data Protection

**This repository contains ZERO real data.**

All files in `data/sample/` are:
- âœ… **Synthetically generated** using Python's Faker library
- âœ… **Statistically similar** to real data (same patterns, distributions)
- âœ… **Safe to share publicly** (no PII, no confidential info)

### Production Implementation

The original production pipeline:
- ğŸ” Processes confidential participant data (SSNs, amounts, tax codes)
- ğŸ” Runs on secure internal servers (no cloud exposure)
- ğŸ” Outputs stored in encrypted, access-controlled folders
- ğŸ” Audit trail logged for compliance reviews
- ğŸ” Follows GDPR, SOC 2, and financial regulations

### Why Synthetic Data?

Using synthetic data allows me to:
1. **Showcase technical skills** without violating confidentiality
2. **Make project reproducible** - anyone can run the code
3. **Demonstrate privacy-first thinking** - critical in finance/healthcare
4. **Comply with employer IP agreements** - no proprietary data shared

---

## ğŸ“œ License

MIT License - See [LICENSE](LICENSE) file for details.

This project is part of my data analysis portfolio and available for educational purposes.

---

## ğŸ‘¨â€ğŸ’» About Me

I'm **Manuel Reyes**, transitioning into data science after 6 years in trading and operations. This project combines my domain expertise in finance with new technical skills in Python and data engineering.

**What makes this project special:**
- Built to solve a real business problem I experienced firsthand
- Demonstrates end-to-end thinking: problem â†’ solution â†’ impact
- Portfolio-ready code with privacy compliance
- Clear business value tied to reduced manual review and audit-ready outputs

### Connect With Me

- ğŸ’¼ [LinkedIn](https://linkedin.com/in/mr410)
- ğŸ™ [GitHub](https://github.com/manuel-reyes-ml)
- ğŸ“§ [Email](mailto:manuelreyesv410@gmail.com)

### Other Projects

- ğŸ“ˆ **[Trading Attention Tracker](https://github.com/manuel-reyes-ml/trading-attention-tracker)** - Correlating news/Wikipedia attention with stock trading volume
- ğŸ“š **[Learning Journey](https://github.com/manuel-reyes-ml/learning_journey)** - 37-month roadmap: Data Analyst â†’ ML Engineer â†’ LLM Engineer
- ğŸ¯ **[Data Portfolio](https://github.com/manuel-reyes-ml/data-portfolio)** - Collection of data analysis projects

---

## ğŸ™ Acknowledgments

- Operations team for business requirements and feedback
- Compliance team for privacy guidance
- Colleagues who tested early versions

---

## ğŸ“ Questions or Feedback?

- ğŸ’¬ Open an [Issue](https://github.com/manuel-reyes-ml/1099_reconciliation_pipeline/issues)
- ğŸŒŸ Star this repo if you found it helpful
- ğŸ´ Fork and adapt for your own reconciliation needs

---

**â­ If this project helped you or gave you ideas, please give it a star! It helps others discover it.**

---

*Last updated: January 2026*
